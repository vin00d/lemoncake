{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../dataset/mimiciv/mit_pretrained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting**\n",
    "- https://glassboxmedicine.com/2019/09/15/best-use-of-train-val-test-splits-with-tips-for-medical-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 45052: expected 6405 fields, saw 7173\n",
      "Skipping line 45053: expected 6405 fields, saw 7173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embs = pd.read_csv(f'{datapath}/cxr_ic_fusion_1103.csv', on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read line 45052 from a csv file\n",
    "# with open('../dataset/mimiciv/mit_pretrained/cxr_ic_fusion_1103.csv', 'r') as f:\n",
    "#     lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the erring lines to a new file\n",
    "# with open('err_lines.txt', 'w') as f:\n",
    "#     for line in lines[45050:45055]:\n",
    "#         f.write(line + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45050, 6405)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embs), len(embs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'validate', 'test'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.split.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8655"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.haim_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [c for c in embs.columns if c.startswith(('haim_id', 'de_', 'vd', 'vmd', 'ts_ce', 'ts_le', 'ts_pe', 'n_ecg', 'n_ech', 'split'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice multiple groups of columns from embs\n",
    "x = embs.loc[:, x_cols]\n",
    "y = embs.loc[:, 'split': 'Pneumothorax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.columns), len(y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split as Sefined in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each split:\n",
      "train: 43,738\n",
      "val: 321\n",
      "test: 991\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in each split:\")\n",
    "print(f\"train: {len(embs[embs.split == 'train']):,}\")\n",
    "print(f\"val: {len(embs[embs.split == 'validate']):,}\")\n",
    "print(f\"test: {len(embs[embs.split == 'test']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages of train, validate, test: \n",
      "train: 97.088%\n",
      "val: 0.713%\n",
      "test: 2.200%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentages of train, validate, test: \")\n",
    "print(f\"train: {len(embs[embs.split == 'train'])/len(embs)*100:.3f}%\")\n",
    "print(f\"val: {len(embs[embs.split == 'validate'])/len(embs)*100:.3f}%\")\n",
    "print(f\"test: {len(embs[embs.split == 'test'])/len(embs)*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = all rows where split == 'train' and all columns except 'split'\n",
    "x_train = x.loc[x.split == 'train', x.columns != 'split']\n",
    "y_train = y.loc[x.split == 'train', y.columns != 'split']\n",
    "\n",
    "x_val = x.loc[x.split == 'validate', x.columns != 'split']\n",
    "y_val = y.loc[x.split == 'validate', y.columns != 'split']\n",
    "\n",
    "x_test = x.loc[x.split == 'test', x.columns != 'split']\n",
    "y_test = y.loc[x.split == 'test', y.columns != 'split']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split on HAIM_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT**\n",
    "- Multiple HAIM IDs are used for a single patient (look in HAIM code for details)\n",
    "- HAIM_ID is a unique combination of `subject_id`, `hadm_id` and `stay_id`\n",
    "- **So need to revisit splitting strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8655"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haim_ids = pd.DataFrame(embs.haim_id.unique())\n",
    "len(haim_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_patients(patients, valid_pct=0.2, test_pct=0.2, random_state=1234):\n",
    "    '''Split the patients dataframe'''\n",
    "    train_pct = 1 - (valid_pct + test_pct)\n",
    "    print(f'Splits:: train: {train_pct}, valid: {valid_pct}, test: {test_pct}')\n",
    "    patients = patients.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return np.split(patients, [int(train_pct*len(patients)), int((train_pct+valid_pct)*len(patients))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits:: train: 0.8, valid: 0.1, test: 0.1\n"
     ]
    }
   ],
   "source": [
    "train_haim_ids, val_haim_ids, test_haim_ids = split_patients(haim_ids, valid_pct=0.1, test_pct=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6924, 865, 866)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_haim_ids), len(val_haim_ids), len(test_haim_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'haim_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5480/673685331.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x_train = all rows with haim_id in train_haim_ids and all columns except 'split'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhaim_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_haim_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhaim_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_haim_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lemoncake/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'haim_id'"
     ]
    }
   ],
   "source": [
    "# x_train = all rows with haim_id in train_haim_ids and all columns except 'split'\n",
    "x_train = x.loc[x.haim_id.isin(train_haim_ids[0].values.flatten()), x.columns != 'split']\n",
    "y_train = y.loc[x.haim_id.isin(train_haim_ids[0].values.flatten()), y.columns != 'split']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirming shapes of train, val, test splits:\n",
      "x_train: (43738, 4041), y_train: (43738, 13)\n",
      "x_val: (321, 4041), y_val: (321, 13)\n",
      "x_test: (991, 4041), y_test: (991, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Confirming shapes of train, val, test splits:\")\n",
    "print(f\"x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"x_val: {x_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"x_test: {x_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
      "       'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity',\n",
      "       'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia',\n",
      "       'Pneumothorax'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(y_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to files into a new folder called splits\n",
    "if not os.path.exists(f'{datapath}/splits'):\n",
    "    os.makedirs(f'{datapath}/splits')\n",
    "    \n",
    "x_train.to_csv(f'{datapath}/splits/x_train.csv', index=False)\n",
    "y_train.to_csv(f'{datapath}/splits/y_train.csv', index=False)\n",
    "\n",
    "x_val.to_csv(f'{datapath}/splits/x_val.csv', index=False)\n",
    "y_val.to_csv(f'{datapath}/splits/y_val.csv', index=False)\n",
    "\n",
    "x_test.to_csv(f'{datapath}/splits/x_test.csv', index=False)\n",
    "y_test.to_csv(f'{datapath}/splits/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(f'{datapath}/splits/x_train.csv')\n",
    "y_train = pd.read_csv(f'{datapath}/splits/y_train.csv')\n",
    "\n",
    "x_val = pd.read_csv(f'{datapath}/splits/x_val.csv')\n",
    "y_val = pd.read_csv(f'{datapath}/splits/y_val.csv')\n",
    "\n",
    "x_test = pd.read_csv(f'{datapath}/splits/x_test.csv')\n",
    "y_test = pd.read_csv(f'{datapath}/splits/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de_0</th>\n",
       "      <th>de_1</th>\n",
       "      <th>de_2</th>\n",
       "      <th>de_3</th>\n",
       "      <th>de_4</th>\n",
       "      <th>de_5</th>\n",
       "      <th>vd_0</th>\n",
       "      <th>vd_1</th>\n",
       "      <th>vd_2</th>\n",
       "      <th>vd_3</th>\n",
       "      <th>...</th>\n",
       "      <th>n_ech_758</th>\n",
       "      <th>n_ech_759</th>\n",
       "      <th>n_ech_760</th>\n",
       "      <th>n_ech_761</th>\n",
       "      <th>n_ech_762</th>\n",
       "      <th>n_ech_763</th>\n",
       "      <th>n_ech_764</th>\n",
       "      <th>n_ech_765</th>\n",
       "      <th>n_ech_766</th>\n",
       "      <th>n_ech_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.120269</td>\n",
       "      <td>0.427006</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>-0.141896</td>\n",
       "      <td>0.041412</td>\n",
       "      <td>-0.061159</td>\n",
       "      <td>-0.126256</td>\n",
       "      <td>-0.234913</td>\n",
       "      <td>-0.014596</td>\n",
       "      <td>0.997139</td>\n",
       "      <td>-0.325668</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>0.479709</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035256</td>\n",
       "      <td>-0.128450</td>\n",
       "      <td>0.231663</td>\n",
       "      <td>-0.123437</td>\n",
       "      <td>-0.073406</td>\n",
       "      <td>-0.287570</td>\n",
       "      <td>0.059177</td>\n",
       "      <td>0.988906</td>\n",
       "      <td>-0.340464</td>\n",
       "      <td>0.999796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020457</td>\n",
       "      <td>0.253198</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>-0.195788</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>-0.064522</td>\n",
       "      <td>-0.054913</td>\n",
       "      <td>-0.214809</td>\n",
       "      <td>-0.019572</td>\n",
       "      <td>0.995771</td>\n",
       "      <td>-0.260190</td>\n",
       "      <td>0.999820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.107806</td>\n",
       "      <td>0.385208</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>-0.141896</td>\n",
       "      <td>0.041412</td>\n",
       "      <td>-0.061159</td>\n",
       "      <td>-0.126256</td>\n",
       "      <td>-0.234913</td>\n",
       "      <td>-0.014596</td>\n",
       "      <td>0.997139</td>\n",
       "      <td>-0.325668</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068780</td>\n",
       "      <td>0.281578</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>-0.141896</td>\n",
       "      <td>0.041412</td>\n",
       "      <td>-0.061159</td>\n",
       "      <td>-0.126256</td>\n",
       "      <td>-0.234913</td>\n",
       "      <td>-0.014596</td>\n",
       "      <td>0.997139</td>\n",
       "      <td>-0.325668</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   de_0  de_1  de_2  de_3  de_4  de_5      vd_0      vd_1      vd_2      vd_3  \\\n",
       "0  53.0     0     7     2     1     1  0.000185  0.120269  0.427006  0.004908   \n",
       "1  53.0     0     4     2     1     1  0.000000  0.024619  0.479709  0.006753   \n",
       "2  69.0     1     7     1     1     1  0.000000  0.020457  0.253198  0.016274   \n",
       "3  53.0     0     7     2     1     1  0.003060  0.107806  0.385208  0.002662   \n",
       "4  53.0     0     7     2     1     1  0.000000  0.068780  0.281578  0.018962   \n",
       "\n",
       "   ...  n_ech_758  n_ech_759  n_ech_760  n_ech_761  n_ech_762  n_ech_763  \\\n",
       "0  ...   0.043556  -0.141896   0.041412  -0.061159  -0.126256  -0.234913   \n",
       "1  ...  -0.035256  -0.128450   0.231663  -0.123437  -0.073406  -0.287570   \n",
       "2  ...   0.085233  -0.195788   0.066648  -0.064522  -0.054913  -0.214809   \n",
       "3  ...   0.043556  -0.141896   0.041412  -0.061159  -0.126256  -0.234913   \n",
       "4  ...   0.043556  -0.141896   0.041412  -0.061159  -0.126256  -0.234913   \n",
       "\n",
       "   n_ech_764  n_ech_765  n_ech_766  n_ech_767  \n",
       "0  -0.014596   0.997139  -0.325668   0.999876  \n",
       "1   0.059177   0.988906  -0.340464   0.999796  \n",
       "2  -0.019572   0.995771  -0.260190   0.999820  \n",
       "3  -0.014596   0.997139  -0.325668   0.999876  \n",
       "4  -0.014596   0.997139  -0.325668   0.999876  \n",
       "\n",
       "[5 rows x 4041 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0          1.0           1.0            NaN    1.0   \n",
       "1          NaN           NaN            NaN    NaN   \n",
       "2          NaN           0.0            1.0    NaN   \n",
       "3          1.0           1.0            NaN    1.0   \n",
       "4          NaN           NaN            NaN    NaN   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         NaN       NaN          NaN           1.0   \n",
       "1                         NaN       NaN          NaN           NaN   \n",
       "2                         NaN       NaN          NaN           NaN   \n",
       "3                         NaN       NaN          NaN           1.0   \n",
       "4                         NaN       NaN          NaN           1.0   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \n",
       "0         NaN               NaN            NaN        NaN           NaN  \n",
       "1         1.0               NaN            NaN        NaN           0.0  \n",
       "2         NaN               0.0            NaN        NaN           NaN  \n",
       "3         NaN               NaN            NaN        NaN           NaN  \n",
       "4         NaN               1.0            NaN       -1.0           NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Fixing `-1`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis --> [ 1. nan  0. -1.]\n",
      "Cardiomegaly --> [ 1. nan  0. -1.]\n",
      "Consolidation --> [nan  1.  0. -1.]\n",
      "Edema --> [ 1. nan  0. -1.]\n",
      "Enlarged Cardiomediastinum --> [nan  1.  0. -1.]\n",
      "Fracture --> [nan  1. -1.  0.]\n",
      "Lung Lesion --> [nan  1. -1.  0.]\n",
      "Lung Opacity --> [ 1. nan -1.  0.]\n",
      "No Finding --> [nan  1.]\n",
      "Pleural Effusion --> [nan  0.  1. -1.]\n",
      "Pleural Other --> [nan  1. -1.  0.]\n",
      "Pneumonia --> [nan -1.  0.  1.]\n",
      "Pneumothorax --> [nan  0.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "for col in y_train.columns:\n",
    "    print(f\"{col} --> {y_train[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 12231.0,\n",
       " 'Cardiomegaly': 13285.0,\n",
       " 'Consolidation': 2463.0,\n",
       " 'Edema': 6614.0,\n",
       " 'Enlarged Cardiomediastinum': -1133.0,\n",
       " 'Fracture': 474.0,\n",
       " 'Lung Lesion': 743.0,\n",
       " 'Lung Opacity': 12344.0,\n",
       " 'No Finding': 5013.0,\n",
       " 'Pleural Effusion': 19011.0,\n",
       " 'Pleural Other': 220.0,\n",
       " 'Pneumonia': 397.0,\n",
       " 'Pneumothorax': 2519.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum(axis=0).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis --> [1. 0.]\n",
      "Cardiomegaly --> [1. 0.]\n",
      "Consolidation --> [0. 1.]\n",
      "Edema --> [1. 0.]\n",
      "Enlarged Cardiomediastinum --> [0. 1.]\n",
      "Fracture --> [0. 1.]\n",
      "Lung Lesion --> [0. 1.]\n",
      "Lung Opacity --> [1. 0.]\n",
      "No Finding --> [0. 1.]\n",
      "Pleural Effusion --> [0. 1.]\n",
      "Pleural Other --> [0. 1.]\n",
      "Pneumonia --> [0. 1.]\n",
      "Pneumothorax --> [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "new_y_train = y_train.fillna(0).replace(-1, 0)\n",
    "for col in new_y_train.columns:\n",
    "    print(f\"{col} --> {new_y_train[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 14336.0,\n",
       " 'Cardiomegaly': 15279.0,\n",
       " 'Consolidation': 3558.0,\n",
       " 'Edema': 10310.0,\n",
       " 'Enlarged Cardiomediastinum': 2309.0,\n",
       " 'Fracture': 508.0,\n",
       " 'Lung Lesion': 860.0,\n",
       " 'Lung Opacity': 13235.0,\n",
       " 'No Finding': 5013.0,\n",
       " 'Pleural Effusion': 20322.0,\n",
       " 'Pleural Other': 305.0,\n",
       " 'Pneumonia': 3730.0,\n",
       " 'Pneumothorax': 2902.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_train.sum(axis=0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lemoncake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
