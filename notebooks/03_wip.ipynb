{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing lemoncake package - to be able to import code that does not need changing\n",
    "import sys\n",
    "sys.path.append('../') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemoncake.data import get_datasets, get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 14336.0,\n",
       " 'Cardiomegaly': 15279.0,\n",
       " 'Consolidation': 3558.0,\n",
       " 'Edema': 10310.0,\n",
       " 'Enlarged Cardiomediastinum': 2309.0,\n",
       " 'Fracture': 508.0,\n",
       " 'Lung Lesion': 860.0,\n",
       " 'Lung Opacity': 13235.0,\n",
       " 'No Finding': 5013.0,\n",
       " 'Pleural Effusion': 20322.0,\n",
       " 'Pleural Other': 305.0,\n",
       " 'Pneumonia': 3730.0,\n",
       " 'Pneumothorax': 2902.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43738"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  2.,   2.,  11.,   3.,  18.,  85.,  50.,   2.,   8.,   1., 142.,  11.,\n",
       "          14.]),\n",
       " tensor([ 3.,  2., 20.,  3., 22., inf, 39.,  2.,  8.,  2., 52.,  9., 10.]),\n",
       " tensor([ 1.,  2., 16.,  2., 14., 75., 46.,  2., 13.,  1., 82., 10., 19.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_pos_weights(), val_ds.get_pos_weights(), test_ds.get_pos_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dataloaders({'train': train_ds, 'valid': val_ds, 'test': test_ds}, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl, test_dl = dls['train'], dls['valid'], dls['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_dl))\n",
    "# x, y = batch['x'], batch['y']\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemoncake.model import *\n",
    "from pytorch_lightning import Trainer, seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = MultimodalBERT(\n",
    "    train_ds.get_pos_weights(),\n",
    "    val_ds.get_pos_weights(),\n",
    "    hidden=384,\n",
    "    n_layers=6,\n",
    "    attn_heads=6,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultimodalBERT(\n",
    "    train_ds.get_pos_weights(),\n",
    "    val_ds.get_pos_weights(),\n",
    "    hidden=32,\n",
    "    n_layers=2,\n",
    "    attn_heads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_ds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = batch[\"x\"], batch[\"y\"]\n",
    "# x.shape, y.shape, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 4041]), torch.Size([32, 13]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "x, y = batch['x'], batch['y']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(x.device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 13])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape#, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 13])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape#, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3340, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BCEWithLogitsLoss(pos_weight=train_ds.get_pos_weights())(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Karpathy's \n",
    "    - [Coment about init in the README](https://github.com/karpathy/ng-video-lecture)\n",
    "    - [nanoGPT init](https://github.com/karpathy/nanoGPT/blob/a82b33b525ca9855d705656387698e13eb8e8d4b/model.py#L147)\n",
    "- StackExchange - [Is there a proper initialization technique for the weight matrices in multi-head attention?](https://ai.stackexchange.com/questions/30491/is-there-a-proper-initialization-technique-for-the-weight-matrices-in-multi-head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimodalBERT(\n",
       "  (train_loss_fn): BCEWithLogitsLoss()\n",
       "  (valid_loss_fn): BCEWithLogitsLoss()\n",
       "  (preprocessor): VectorPreProcessor(\n",
       "    (linear): Linear(in_features=4041, out_features=98304, bias=True)\n",
       "  )\n",
       "  (bert): BERT(\n",
       "    (pos_encoder): PositionalEncoding1(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): MultiLabelPredictor(\n",
       "    (linear): Linear(in_features=384, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastai Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "thelist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_multimodalbert(m, initrange, zero_bn=False):\n",
    "    \"\"\"Initialize Multimodal BERT.\"\"\"\n",
    "\n",
    "    # if isinstance(m, (nn.Embedding, nn.EmbeddingBag)):\n",
    "    #     # m.weight.data.uniform_(-initrange, initrange)\n",
    "    #     thelist.append(f\"Initialized {m} with uniform_(-{initrange}, {initrange})\")\n",
    "    if isinstance(m, nn.Linear):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                # nn.init.constant_(param, 0.0)\n",
    "                thelist.append(f\"Initialized {name} with constant_(0.0)\")\n",
    "            elif \"weight\" in name:\n",
    "                # nn.init.kaiming_normal_(param)\n",
    "                thelist.append(f\"Initialized {name} with kaiming_normal_()\")\n",
    "    # if isinstance(m, (nn.BatchNorm1d)):\n",
    "    #     # nn.init.constant_(m.weight, 0.0 if zero_bn else 1.0)\n",
    "    #     thelist.append(f\"Initialized {m} with constant_(0.0 if {zero_bn} else 1.0)\")\n",
    "    for l in m.children():\n",
    "        init_multimodalbert(l, initrange, zero_bn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_multimodalbert(model, 0.02, zero_bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karpathy Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layers.0.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.1.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.2.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.3.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.4.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.5.self_attn.out_proj.weight torch.Size([384, 384])\n"
     ]
    }
   ],
   "source": [
    "    # def _init_weights(self, module):\n",
    "    #         if isinstance(module, nn.Linear):\n",
    "    #             # torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    #             nn.init.kaiming_normal_(module.weight)\n",
    "    #             if module.bias is not None:\n",
    "    #                 torch.nn.init.zeros_(module.bias)\n",
    "    #         # elif isinstance(module, nn.Embedding):\n",
    "    #         #     torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.endswith('proj.weight'):\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42, workers=True)\n",
    "trainer = Trainer(max_epochs=2, precision='16-mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "2 | preprocessor  | VectorPreProcessor  | 33.1 M\n",
      "3 | bert          | BERT                | 25.4 K\n",
      "4 | predictor     | MultiLabelPredictor | 429   \n",
      "5 | train_metrics | MetricCollection    | 0     \n",
      "6 | valid_metrics | MetricCollection    | 0     \n",
      "7 | test_metrics  | MetricCollection    | 0     \n",
      "------------------------------------------------------\n",
      "33.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 M    Total params\n",
      "132.552   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9a7176d7404eeba4cef49f88b5caaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemoncake/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:42: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd45ebe71c343fd8a4b54311fa0c77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb73fb09e1da4342a9bac05529723cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a714bf46c2a449ffbeea92958e822682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "2 | preprocessor  | VectorPreProcessor  | 397 M \n",
      "3 | bert          | BERT                | 10.6 M\n",
      "4 | predictor     | MultiLabelPredictor | 5.0 K \n",
      "------------------------------------------------------\n",
      "407 M     Trainable params\n",
      "0         Non-trainable params\n",
      "407 M     Total params\n",
      "1,631.986 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e533ce9d80248c49afe9c35e97edfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0220c079d79f4184ba7048de773563c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a93747a4414dbc832997f442e4513a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd2127dde9e471aae392891c65ef098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"./lightning_logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Issues / Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train, valid, test split\n",
    "2. What to do about \"-1\" in labels\n",
    "    - currently doing `y = y.fillna(0).replace(-1, 0)`\n",
    "    - i.e. replacing `NaN` and `-1` with zeros\n",
    "    - According to the HAIM paper - `-1` is not determined and they have eliminated everything other than 1 and 0 in their training.\n",
    "3. Model size options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lemoncake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
