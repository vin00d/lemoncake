{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing lemoncake package - to be able to import code that does not need changing\n",
    "import sys\n",
    "sys.path.append('../') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fastai forums discussion - [Getting some NaN, where to start investigating?](https://forums.fast.ai/t/getting-some-nan-where-to-start-investigating/64707/5?replies_to_post_number=4)\n",
    "    - No mixed precision\n",
    "- Pytorch issues discussion - [Decrease lr](https://github.com/pytorch/pytorch/issues/40497#issuecomment-680409016)\n",
    "    - [Troubleshooting options](https://github.com/pytorch/pytorch/issues/40497#issuecomment-707383143)\n",
    "        - [Prefer binary_cross_entropy_with_logits over binary_cross_entropy](https://pytorch.org/docs/stable/amp.html#prefer-binary-cross-entropy-with-logits-over-binary-cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-06, 0.001, 3e-05)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-6, 1e-3, 3e-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemoncake.data import get_datasets, get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_ds.label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds.label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35591, 4886, 4573)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  2.,   2.,  11.,   3.,  18.,  80.,  52.,   2.,   8.,   1., 136.,  11.,\n",
       "          14.]),\n",
       " tensor([  2.,   2.,  12.,   3.,  20., 118.,  42.,   2.,   9.,   1., 157.,  10.,\n",
       "          14.]),\n",
       " tensor([  2.,   2.,  12.,   4.,  16., 119.,  43.,   2.,   8.,   1., 142.,  11.,\n",
       "          14.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_pos_weights(), val_ds.get_pos_weights(), test_ds.get_pos_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dataloaders({'train': train_ds, 'valid': val_ds, 'test': test_ds}, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl, test_dl = dls['train'], dls['valid'], dls['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 4041]), torch.Size([64, 13]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dl))\n",
    "x, y = batch['x'], batch['y']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemoncake.model import *\n",
    "from pytorch_lightning import Trainer, seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = MultimodalBERT(\n",
    "    train_ds.get_pos_weights(),\n",
    "    val_ds.get_pos_weights(),\n",
    "    hidden=384,\n",
    "    n_layers=6,\n",
    "    attn_heads=6,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultimodalBERT(\n",
    "    train_ds.get_pos_weights(),\n",
    "    val_ds.get_pos_weights(),\n",
    "    hidden=32,\n",
    "    n_layers=2,\n",
    "    attn_heads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = train_ds[0:10]\n",
    "# x, y = batch[\"x\"], batch[\"y\"]\n",
    "# x.shape, y.shape, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 4041]), torch.Size([64, 13]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dl))\n",
    "x, y = batch['x'], batch['y']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(x.device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 13])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype, y_hat.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor(nan, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_loss = nn.BCEWithLogitsLoss(pos_weight=val_ds.get_pos_weights())(y_hat, y)\n",
    "f_loss = F.binary_cross_entropy_with_logits(y_hat, y, pos_weight=val_ds.get_pos_weights())\n",
    "nn_loss, f_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Karpathy's \n",
    "    - [Coment about init in the README](https://github.com/karpathy/ng-video-lecture)\n",
    "    - [nanoGPT init](https://github.com/karpathy/nanoGPT/blob/a82b33b525ca9855d705656387698e13eb8e8d4b/model.py#L147)\n",
    "- StackExchange - [Is there a proper initialization technique for the weight matrices in multi-head attention?](https://ai.stackexchange.com/questions/30491/is-there-a-proper-initialization-technique-for-the-weight-matrices-in-multi-head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimodalBERT(\n",
       "  (train_loss_fn): BCEWithLogitsLoss()\n",
       "  (valid_loss_fn): BCEWithLogitsLoss()\n",
       "  (preprocessor): VectorPreProcessor(\n",
       "    (linear): Linear(in_features=4041, out_features=98304, bias=True)\n",
       "  )\n",
       "  (bert): BERT(\n",
       "    (pos_encoder): PositionalEncoding1(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): MultiLabelPredictor(\n",
       "    (linear): Linear(in_features=384, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastai Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thelist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_multimodalbert(m, initrange, zero_bn=False):\n",
    "    \"\"\"Initialize Multimodal BERT.\"\"\"\n",
    "\n",
    "    # if isinstance(m, (nn.Embedding, nn.EmbeddingBag)):\n",
    "    #     # m.weight.data.uniform_(-initrange, initrange)\n",
    "    #     thelist.append(f\"Initialized {m} with uniform_(-{initrange}, {initrange})\")\n",
    "    if isinstance(m, nn.Linear):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                # nn.init.constant_(param, 0.0)\n",
    "                thelist.append(f\"Initialized {name} with constant_(0.0)\")\n",
    "            elif \"weight\" in name:\n",
    "                # nn.init.kaiming_normal_(param)\n",
    "                thelist.append(f\"Initialized {name} with kaiming_normal_()\")\n",
    "    # if isinstance(m, (nn.BatchNorm1d)):\n",
    "    #     # nn.init.constant_(m.weight, 0.0 if zero_bn else 1.0)\n",
    "    #     thelist.append(f\"Initialized {m} with constant_(0.0 if {zero_bn} else 1.0)\")\n",
    "    for l in m.children():\n",
    "        init_multimodalbert(l, initrange, zero_bn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_multimodalbert(model, 0.02, zero_bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karpathy Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layers.0.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.1.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.2.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.3.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.4.self_attn.out_proj.weight torch.Size([384, 384])\n",
      "bert.encoder.layers.5.self_attn.out_proj.weight torch.Size([384, 384])\n"
     ]
    }
   ],
   "source": [
    "    # def _init_weights(self, module):\n",
    "    #         if isinstance(module, nn.Linear):\n",
    "    #             # torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    #             nn.init.kaiming_normal_(module.weight)\n",
    "    #             if module.bias is not None:\n",
    "    #                 torch.nn.init.zeros_(module.bias)\n",
    "    #         # elif isinstance(module, nn.Embedding):\n",
    "    #         #     torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.endswith('proj.weight'):\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42, workers=True)\n",
    "trainer = Trainer(max_epochs=20) #, precision='16-mixed') #detect_anomaly=True) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "2 | preprocessor  | VectorPreProcessor  | 33.1 M\n",
      "3 | bert          | BERT                | 25.4 K\n",
      "4 | predictor     | MultiLabelPredictor | 429   \n",
      "------------------------------------------------------\n",
      "33.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 M    Total params\n",
      "132.552   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470e08045d594587b68f5d2ed17ee6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62372d839cf481dbd2cd8247faa60e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c857014854fafa8efc38b2d26e033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc1a18484ad4699b84d52a9283a86f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2c9a511810419498e2149edcefe117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b6f06c01844ebc840c7da1a2a4dc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6462949b5e1c4f64a0c7afb8e55ced6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f04e34c93484bbca0214437d3ade869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59eb2252d25746bf9e6bf49f2a9c0e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44f3d5f2407420db660917ce5bb6b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b33b19bec854c0bb6c62ae36e15683c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a1936f93d548b2b260c164a311a7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss   | 0     \n",
      "2 | preprocessor  | VectorPreProcessor  | 397 M \n",
      "3 | bert          | BERT                | 10.6 M\n",
      "4 | predictor     | MultiLabelPredictor | 5.0 K \n",
      "------------------------------------------------------\n",
      "407 M     Trainable params\n",
      "0         Non-trainable params\n",
      "407 M     Total params\n",
      "1,631.986 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e533ce9d80248c49afe9c35e97edfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0220c079d79f4184ba7048de773563c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a93747a4414dbc832997f442e4513a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd2127dde9e471aae392891c65ef098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"./lightning_logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Issues / Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train, valid, test split\n",
    "2. What to do about \"-1\" in labels\n",
    "    - currently doing `y = y.fillna(0).replace(-1, 0)`\n",
    "    - i.e. replacing `NaN` and `-1` with zeros\n",
    "    - According to the HAIM paper - `-1` is not determined and they have eliminated everything other than 1 and 0 in their training.\n",
    "3. Model size options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lemoncake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
